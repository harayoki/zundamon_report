"# ReportVox\n\nReportVox は、音声ファイルを「文字起こし → 話者分離 → 口調変換 → VOICEVOX での音声生成 → WAV/MP3 出力」まで自動化する CLI ツールです。NotebookLM などが生成する m4a を扱うため ffmpeg は必須で、`ffmpeg -version` が通る状態にしてください。\n\n## ワークフロー\n1. 入力音声を `work/<run_id>/` にコピー\n2. ffmpeg で WAV に正規化（以降は WAV のみ使用）\n3. Whisper で文字起こし（セグメント JSON 保存）\n4. pyannote.audio で話者分離（1/2人自動判定対応）\n5. Whisper セグメントと突合して話者ラベルを付与\n6. 1人相当ならずんだもん全編、2人なら発話量の多い方を speaker1 としてキャラ割当\n7. （オプション）口調変換、定型句の自動挿入\n8. VOICEVOX Engine HTTP API で行ごとに合成\n9. wav を結合して `out/<stem>_report.wav` を生成\n10. `--mp3` 指定時に MP3 を追加生成（ffmpeg 使用）\n\n## インストール\nPython 3.11+ を想定しています。\n\n```bash\npython -m venv .venv\nsource .venv/bin/activate  # Windows: .venv\\\\Scripts\\\\activate\npip install --upgrade pip\npip install -r requirements.txt\n```\n\n### ffmpeg 導入例\n- Windows: https://www.gyan.dev/ffmpeg/builds/ から取得し、`ffmpeg/bin` を PATH に追加\n- macOS: `brew install ffmpeg`\n- Linux (Debian/Ubuntu): `sudo apt-get install ffmpeg`\n- インストール後、`ffmpeg -version` が成功することを確認してください。\n\n## 依存サービス\n- VOICEVOX Engine（ローカル起動を想定）\n  - 例: `VOICEVOX_ENGINE_HOME=/path/to/engine ./run --host 127.0.0.1 --port 50021`\n- pyannote.audio の実行には Hugging Face Token が必要な場合があります。\n  - 環境変数 `PYANNOTE_TOKEN` または CLI 引数 `--hf-token` で指定してください。\n\n## 使い方\n```bash\n# 自動話者判定、デフォルト（ずんだもん+めたん）\npython -m reportvox input.wav\n\n# 話者を強制 1 人（ずんだもんのみ）\npython -m reportvox input.wav --speakers 1\n\n# 話者 2 人を強制し、キャラ指定\npython -m reportvox input.wav --speakers 2 --speaker1 zundamon --speaker2 metan\n\n# MP3 も生成\npython -m reportvox input.wav --mp3 --bitrate 192k\n\n# VOICEVOX の URL を指定\npython -m reportvox input.wav --voicevox-url http://127.0.0.1:50021\n```\n\n## characters の追加方法\n`characters/<id>/` ディレクトリを作り、`meta.yaml` と `examples.json` を配置します。`meta.yaml` では VOICEVOX の `speaker_id` を設定し、口調情報や定型句を登録してください。`examples.json` には短文例を配列で追加します。\n\n## 出力\n- 常に: `out/<入力ファイル名>_report.wav`\n- `--mp3` 指定時: `out/<入力ファイル名>_report.mp3`\n\n## 注意事項\n- VOICEVOX が起動していない場合、合成でエラーとなります。\n- ffmpeg が無い場合は実行開始時にエラーとなります。\n- LLM 口調変換は差し替えやすい構造ですが、デフォルトではスキップされます。\n"
